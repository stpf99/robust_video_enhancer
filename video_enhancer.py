#!/usr/bin/env python3
"""
Wzmacniacz wideo z ≈Çagodnym, naturalnym przetwarzaniem
Eliminuje ostre strefy i zachowuje p≈Çynne przej≈õcia
"""

import cv2
import numpy as np
import sys
import os
import subprocess
import tempfile
from pathlib import Path

class SmoothVideoEnhancer:
    """Wzmacniacz z ≈Çagodnym, naturalnym przetwarzaniem"""
    
    def __init__(self):
        self.temp_dir = tempfile.mkdtemp(prefix='video_enhance_')
        print(f"üìÅ Katalog tymczasowy: {self.temp_dir}")
    
    def enhance_frame_smooth(self, frame):
        """≈Åagodne wzmocnienie klatki - eliminuje ostre strefy"""
        if frame is None:
            return None
        
        # Konwersja do float32 dla lepszej precyzji
        frame_float = frame.astype(np.float32) / 255.0
        
        # Metoda 1: Gamma correction z adaptacjƒÖ
        enhanced = self.adaptive_gamma_correction(frame_float)
        
        # Metoda 2: ≈Åagodne wzmocnienie kontrastu
        enhanced = self.gentle_contrast_enhancement(enhanced)
        
        # Metoda 3: Selektywne wyostrzanie
        enhanced = self.selective_sharpening(enhanced, frame_float)
        
        # Metoda 4: Redukcja szum√≥w
        enhanced = self.noise_reduction(enhanced)
        
        # Powr√≥t do uint8
        enhanced = np.clip(enhanced * 255.0, 0, 255).astype(np.uint8)
        
        return enhanced
    
    def adaptive_gamma_correction(self, frame):
        """Adaptacyjna korekcja gamma bazujƒÖca na jasno≈õci obrazu"""
        # Konwersja do HSV
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # Analiza histogramu kana≈Çu V (jasno≈õƒá)
        hist, _ = np.histogram(hsv[:,:,2], bins=256, range=(0, 1))
        
        # Oblicz ≈õredniƒÖ jasno≈õƒá
        mean_brightness = np.mean(hsv[:,:,2])
        
        # Adaptacyjne gamma - ciemne obrazy dostajƒÖ wiƒôcej rozja≈õnienia
        if mean_brightness < 0.3:
            gamma = 0.7  # Rozja≈õnij ciemne obszary
        elif mean_brightness > 0.7:
            gamma = 1.3  # Przyciemnij jasne obszary
        else:
            gamma = 1.0  # Neutralne
        
        # Zastosuj korekcjƒô gamma tylko do kana≈Çu jasno≈õci
        hsv[:,:,2] = np.power(hsv[:,:,2], gamma)
        
        # Powr√≥t do BGR
        enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        return enhanced
    
    def gentle_contrast_enhancement(self, frame):
        """≈Åagodne wzmocnienie kontrastu bez ostrych przej≈õƒá"""
        # Konwersja do LAB
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # Bardzo ≈Çagodne CLAHE
        clahe = cv2.createCLAHE(
            clipLimit=1.5,      # Zmniejszone z 3.0
            tileGridSize=(16,16) # Wiƒôksze kafelki = mniej artefakt√≥w
        )
        l_enhanced = clahe.apply((l * 255).astype(np.uint8)).astype(np.float32) / 255.0
        
        # Mieszanie z orygina≈Çem (50/50) dla ≈Çagodno≈õci
        l_blended = 0.6 * l_enhanced + 0.4 * l
        
        # Rekombinacja
        lab_enhanced = cv2.merge([l_blended, a, b])
        bgr_enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)
        
        return bgr_enhanced
    
    def selective_sharpening(self, frame, original):
        """Selektywne wyostrzanie - tylko tam gdzie potrzeba"""
        # Gaussian blur dla maski krawƒôdzi
        blurred = cv2.GaussianBlur(frame, (0, 0), 1.0)
        
        # Maska krawƒôdzi (gdzie sƒÖ szczeg√≥≈Çy do wyostrzenia)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)
        edge_mask = edges.astype(np.float32) / 255.0
        
        # Rozszerz maskƒô dla p≈Çynniejszych przej≈õƒá
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        edge_mask = cv2.dilate(edge_mask, kernel, iterations=1)
        edge_mask = cv2.GaussianBlur(edge_mask, (5, 5), 2.0)
        
        # Unsharp mask - bardzo ≈Çagodny
        unsharp = frame + 0.3 * (frame - blurred)
        
        # Zastosuj wyostrzanie tylko na krawƒôdziach
        result = np.zeros_like(frame)
        for c in range(3):
            result[:,:,c] = frame[:,:,c] * (1 - edge_mask) + unsharp[:,:,c] * edge_mask
        
        return result
    
    def noise_reduction(self, frame):
        """≈Åagodna redukcja szum√≥w"""
        # Bilateral filter - zachowuje krawƒôdzie, redukuje szumy
        denoised = cv2.bilateralFilter(
            (frame * 255).astype(np.uint8), 
            d=5,           # ≈örednica sƒÖsiedztwa
            sigmaColor=25, # Pr√≥g kolor√≥w
            sigmaSpace=25  # Pr√≥g przestrzeni
        ).astype(np.float32) / 255.0
        
        # Mieszaj z orygina≈Çem dla naturalno≈õci
        return 0.7 * frame + 0.3 * denoised
    
    def enhance_frame_alternative(self, frame):
        """Alternatywna metoda - jeszcze ≈Çagodniejsza"""
        if frame is None:
            return None
        
        # Metoda bazujƒÖca na histogram stretching
        frame_float = frame.astype(np.float32)
        
        # Dla ka≈ºdego kana≈Çu osobno
        enhanced = np.zeros_like(frame_float)
        for c in range(3):
            channel = frame_float[:,:,c]
            
            # Percentyle dla miƒôkkiego clippingu
            p2, p98 = np.percentile(channel, (2, 98))
            
            # Soft contrast stretching
            if p98 > p2:
                stretched = (channel - p2) / (p98 - p2)
                stretched = np.clip(stretched, 0, 1)
            else:
                stretched = channel / 255.0
            
            enhanced[:,:,c] = stretched * 255.0
        
        # ≈Åagodne wyostrzanie
        blurred = cv2.GaussianBlur(enhanced, (0, 0), 0.8)
        enhanced = enhanced + 0.2 * (enhanced - blurred)
        
        return np.clip(enhanced, 0, 255).astype(np.uint8)
    
    def compare_methods(self, frame):
        """Por√≥wnanie r√≥≈ºnych metod wzmocnienia"""
        if frame is None:
            return None
        
        # Orygina≈Ç
        original = frame.copy()
        
        # Metoda ≈Çagodna
        smooth = self.enhance_frame_smooth(frame)
        
        # Metoda alternatywna
        alternative = self.enhance_frame_alternative(frame)
        
        # Zwr√≥ƒá najlepszƒÖ metodƒô (mo≈ºna dostosowaƒá)
        return smooth  # Lub alternative, w zale≈ºno≈õci od preferencji
    
    # Reszta metod pozostaje bez zmian
    def diagnose_opencv(self):
        """Diagnostyka OpenCV"""
        print("üîç Diagnostyka OpenCV:")
        print(f"   Wersja: {cv2.__version__}")
        
        codecs = ['mp4v', 'XVID', 'MJPG', 'H264', 'X264']
        available_codecs = []
        
        for codec in codecs:
            try:
                fourcc = cv2.VideoWriter_fourcc(*codec)
                test_writer = cv2.VideoWriter('test.avi', fourcc, 25, (100, 100))
                if test_writer.isOpened():
                    available_codecs.append(codec)
                    print(f"     ‚úì {codec}")
                else:
                    print(f"     ‚úó {codec}")
                test_writer.release()
                try:
                    os.remove('test.avi')
                except:
                    pass
            except Exception as e:
                print(f"     ‚úó {codec} - b≈ÇƒÖd: {e}")
        
        return available_codecs
    
    def check_ffmpeg(self):
        """Sprawd≈∫ dostƒôpno≈õƒá FFmpeg"""
        try:
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                version_line = result.stdout.split('\n')[0]
                print(f"‚úì FFmpeg dostƒôpny: {version_line}")
                return True
        except:
            pass
        
        print("‚úó FFmpeg niedostƒôpny")
        return False
    
    def process_video_smooth(self, input_path, output_path):
        """Przetwarzanie z niezawodnƒÖ metodƒÖ alternative"""
        print(f"üé¨ Rozpoczynam ≈Çagodne przetwarzanie: {input_path}")
        
        # Diagnostyka
        available_codecs = self.diagnose_opencv()
        has_ffmpeg = self.check_ffmpeg()
        
        if not available_codecs and not has_ffmpeg:
            print("‚úó Brak dostƒôpnych metod zapisu wideo!")
            return False
        
        # Informacje o wideo
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            print("‚úó Nie mo≈ºna otworzyƒá pliku wej≈õciowego")
            return False
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"üìπ Wideo: {width}x{height} @ {fps:.2f} FPS, {frame_count} klatek")
        print(f"üé® Metoda wzmocnienia: alternative (histogram stretching)")
        cap.release()
        
        # U≈ºywamy tylko niezawodnej metody alternative
        enhance_func = self.enhance_frame_alternative
        
        # Strategia zapisu - najpierw klatki, potem FFmpeg
        if has_ffmpeg:
            return self.process_via_frames_ffmpeg(input_path, output_path, enhance_func)
        
        return False
    
    def process_via_frames_ffmpeg(self, input_path, output_path, enhance_func):
        """Przetwarzanie przez klatki i FFmpeg"""
        print("üéØ Strategia: Klatki -> FFmpeg")
        
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        frames_dir = os.path.join(self.temp_dir, 'frames')
        os.makedirs(frames_dir, exist_ok=True)
        
        frame_count = 0
        success_count = 0
        
        print("üì∏ Przetwarzanie klatek...")
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            try:
                # Wzmocnienie wybranƒÖ metodƒÖ
                enhanced = enhance_func(frame)
                
                if enhanced is not None:
                    # Zapis jako PNG dla lepszej jako≈õci
                    frame_path = os.path.join(frames_dir, f'frame_{frame_count:06d}.png')
                    success = cv2.imwrite(frame_path, enhanced, 
                                        [cv2.IMWRITE_PNG_COMPRESSION, 1])  # Minimalna kompresja
                    
                    if success:
                        success_count += 1
                
                frame_count += 1
                
                if frame_count % 30 == 0:
                    print(f"   üìä Postƒôp: {success_count}/{frame_count} klatek")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è B≈ÇƒÖd przetwarzania klatki {frame_count}: {e}")
        
        cap.release()
        print(f"‚úÖ Przetworzono {success_count}/{frame_count} klatek")
        
        # Konwersja do wideo przez FFmpeg
        if success_count > 0:
            return self.frames_to_video_ffmpeg(frames_dir, output_path, fps, 'png')
        
        return False
    
    def frames_to_video_ffmpeg(self, frames_dir, output_path, fps, ext='png'):
        """Konwersja klatek do wideo przez FFmpeg z wysokƒÖ jako≈õciƒÖ"""
        print("üé¨ Tworzenie wideo z klatek przez FFmpeg...")
        
        input_pattern = os.path.join(frames_dir, f'frame_%06d.{ext}')
        cmd = [
            'ffmpeg', '-y',
            '-framerate', str(fps),
            '-i', input_pattern,
            '-c:v', 'libx264',
            '-preset', 'slow',      # Lepsza kompresja
            '-crf', '15',           # Bardzo wysoka jako≈õƒá (0-51, ni≈ºsza = lepsza)
            '-pix_fmt', 'yuv420p',
            '-movflags', '+faststart',  # Szybsze ≈Çadowanie
            output_path
        ]
        
        try:
            print(f"   üìù Komenda: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                print(f"‚úÖ FFmpeg sukces: {output_path}")
                return True
            else:
                print(f"‚úó FFmpeg b≈ÇƒÖd: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print("‚úó FFmpeg timeout")
            return False
        except Exception as e:
            print(f"‚úó FFmpeg exception: {e}")
            return False
    
    def cleanup(self):
        """Wyczy≈õƒá pliki tymczasowe"""
        try:
            import shutil
            shutil.rmtree(self.temp_dir)
            print(f"üßπ Wyczyszczono: {self.temp_dir}")
        except Exception as e:
            print(f"‚ö†Ô∏è B≈ÇƒÖd czyszczenia: {e}")

def main():
    if len(sys.argv) < 2:
        print("üé¨ ≈Åagodny Wzmacniacz Wideo")
        print("U≈ºycie: python3 smooth_video_enhancer.py <input.mp4> [output.mp4] [metoda]")
        print("")
        print("Metody wzmocnienia:")
        print("  smooth      - ≈Çagodne wzmocnienie (domy≈õlne)")
        print("  alternative - histogram stretching")
        print("  compare     - automatyczny wyb√≥r najlepszej")
        print("")
        print("Funkcje:")
        print("- Eliminuje ostre strefy i artefakty")
        print("- Zachowuje naturalne przej≈õcia")
        print("- Adaptacyjne wzmocnienie bazowane na zawarto≈õci")
        print("- Selektywne wyostrzanie tylko na krawƒôdziach")
        return
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "smooth_" + os.path.basename(input_file)
    method = sys.argv[3] if len(sys.argv) > 3 else 'smooth'
    
    if not os.path.exists(input_file):
        print(f"‚úó Plik {input_file} nie istnieje")
        return
    
    enhancer = SmoothVideoEnhancer()
    
    try:
        success = enhancer.process_video_smooth(input_file, output_file)
        if success:
            print(f"\nüéâ Sukces! Sprawd≈∫ wyniki: {output_file}")
            print("üìä Wideo zosta≈Ço przetworzone z zachowaniem naturalnych przej≈õƒá")
        else:
            print(f"\nüí• Przetwarzanie nie powiod≈Ço siƒô")
    finally:
        enhancer.cleanup()

if __name__ == "__main__":
    main()