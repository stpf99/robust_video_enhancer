#!/usr/bin/env python3
"""
Wzmacniacz wideo z Å‚agodnym, naturalnym przetwarzaniem
Eliminuje ostre strefy i zachowuje pÅ‚ynne przejÅ›cia
"""

import cv2
import numpy as np
import sys
import os
import subprocess
import tempfile
from pathlib import Path

class SmoothVideoEnhancer:
    """Wzmacniacz z Å‚agodnym, naturalnym przetwarzaniem"""
    
    def __init__(self):
        self.temp_dir = tempfile.mkdtemp(prefix='video_enhance_')
        print(f"ğŸ“ Katalog tymczasowy: {self.temp_dir}")
    
    def enhance_frame_smooth(self, frame):
        """Åagodne wzmocnienie klatki - eliminuje ostre strefy"""
        if frame is None:
            return None
        
        # Konwersja do float32 dla lepszej precyzji
        frame_float = frame.astype(np.float32) / 255.0
        
        # Metoda 1: Gamma correction z adaptacjÄ…
        enhanced = self.adaptive_gamma_correction(frame_float)
        
        # Metoda 2: Åagodne wzmocnienie kontrastu
        enhanced = self.gentle_contrast_enhancement(enhanced)
        
        # Metoda 3: Selektywne wyostrzanie
        enhanced = self.selective_sharpening(enhanced, frame_float)
        
        # Metoda 4: Redukcja szumÃ³w
        enhanced = self.noise_reduction(enhanced)
        
        # PowrÃ³t do uint8
        enhanced = np.clip(enhanced * 255.0, 0, 255).astype(np.uint8)
        
        return enhanced
    
    def adaptive_gamma_correction(self, frame):
        """Adaptacyjna korekcja gamma bazujÄ…ca na jasnoÅ›ci obrazu"""
        # Konwersja do HSV
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # Analiza histogramu kanaÅ‚u V (jasnoÅ›Ä‡)
        hist, _ = np.histogram(hsv[:,:,2], bins=256, range=(0, 1))
        
        # Oblicz Å›redniÄ… jasnoÅ›Ä‡
        mean_brightness = np.mean(hsv[:,:,2])
        
        # Adaptacyjne gamma - ciemne obrazy dostajÄ… wiÄ™cej rozjaÅ›nienia
        if mean_brightness < 0.3:
            gamma = 0.7  # RozjaÅ›nij ciemne obszary
        elif mean_brightness > 0.7:
            gamma = 1.3  # Przyciemnij jasne obszary
        else:
            gamma = 1.0  # Neutralne
        
        # Zastosuj korekcjÄ™ gamma tylko do kanaÅ‚u jasnoÅ›ci
        hsv[:,:,2] = np.power(hsv[:,:,2], gamma)
        
        # PowrÃ³t do BGR
        enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        return enhanced
    
    def gentle_contrast_enhancement(self, frame):
        """Åagodne wzmocnienie kontrastu bez ostrych przejÅ›Ä‡"""
        # Konwersja do LAB
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # Bardzo Å‚agodne CLAHE
        clahe = cv2.createCLAHE(
            clipLimit=1.5,      # Zmniejszone z 3.0
            tileGridSize=(16,16) # WiÄ™ksze kafelki = mniej artefaktÃ³w
        )
        l_enhanced = clahe.apply((l * 255).astype(np.uint8)).astype(np.float32) / 255.0
        
        # Mieszanie z oryginaÅ‚em (50/50) dla Å‚agodnoÅ›ci
        l_blended = 0.6 * l_enhanced + 0.4 * l
        
        # Rekombinacja
        lab_enhanced = cv2.merge([l_blended, a, b])
        bgr_enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)
        
        return bgr_enhanced
    
    def selective_sharpening(self, frame, original):
        """Selektywne wyostrzanie - tylko tam gdzie potrzeba"""
        # Gaussian blur dla maski krawÄ™dzi
        blurred = cv2.GaussianBlur(frame, (0, 0), 1.0)
        
        # Maska krawÄ™dzi (gdzie sÄ… szczegÃ³Å‚y do wyostrzenia)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)
        edge_mask = edges.astype(np.float32) / 255.0
        
        # Rozszerz maskÄ™ dla pÅ‚ynniejszych przejÅ›Ä‡
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        edge_mask = cv2.dilate(edge_mask, kernel, iterations=1)
        edge_mask = cv2.GaussianBlur(edge_mask, (5, 5), 2.0)
        
        # Unsharp mask - bardzo Å‚agodny
        unsharp = frame + 0.3 * (frame - blurred)
        
        # Zastosuj wyostrzanie tylko na krawÄ™dziach
        result = np.zeros_like(frame)
        for c in range(3):
            result[:,:,c] = frame[:,:,c] * (1 - edge_mask) + unsharp[:,:,c] * edge_mask
        
        return result
    
    def noise_reduction(self, frame):
        """Åagodna redukcja szumÃ³w"""
        # Bilateral filter - zachowuje krawÄ™dzie, redukuje szumy
        denoised = cv2.bilateralFilter(
            (frame * 255).astype(np.uint8), 
            d=5,           # Åšrednica sÄ…siedztwa
            sigmaColor=25, # PrÃ³g kolorÃ³w
            sigmaSpace=25  # PrÃ³g przestrzeni
        ).astype(np.float32) / 255.0
        
        # Mieszaj z oryginaÅ‚em dla naturalnoÅ›ci
        return 0.7 * frame + 0.3 * denoised
    
    def enhance_frame_alternative(self, frame):
        """Alternatywna metoda - jeszcze Å‚agodniejsza"""
        if frame is None:
            return None
        
        # Metoda bazujÄ…ca na histogram stretching
        frame_float = frame.astype(np.float32)
        
        # Dla kaÅ¼dego kanaÅ‚u osobno
        enhanced = np.zeros_like(frame_float)
        for c in range(3):
            channel = frame_float[:,:,c]
            
            # Percentyle dla miÄ™kkiego clippingu
            p2, p98 = np.percentile(channel, (2, 98))
            
            # Soft contrast stretching
            if p98 > p2:
                stretched = (channel - p2) / (p98 - p2)
                stretched = np.clip(stretched, 0, 1)
            else:
                stretched = channel / 255.0
            
            enhanced[:,:,c] = stretched * 255.0
        
        # Åagodne wyostrzanie
        blurred = cv2.GaussianBlur(enhanced, (0, 0), 0.8)
        enhanced = enhanced + 0.2 * (enhanced - blurred)
        
        return np.clip(enhanced, 0, 255).astype(np.uint8)
    
    def compare_methods(self, frame):
        """PorÃ³wnanie rÃ³Å¼nych metod wzmocnienia"""
        if frame is None:
            return None
        
        # OryginaÅ‚
        original = frame.copy()
        
        # Metoda Å‚agodna
        smooth = self.enhance_frame_smooth(frame)
        
        # Metoda alternatywna
        alternative = self.enhance_frame_alternative(frame)
        
        # ZwrÃ³Ä‡ najlepszÄ… metodÄ™ (moÅ¼na dostosowaÄ‡)
        return smooth  # Lub alternative, w zaleÅ¼noÅ›ci od preferencji
    
    # Reszta metod pozostaje bez zmian
    def diagnose_opencv(self):
        """Diagnostyka OpenCV"""
        print("ğŸ” Diagnostyka OpenCV:")
        print(f"   Wersja: {cv2.__version__}")
        
        codecs = ['mp4v', 'XVID', 'MJPG', 'H264', 'X264']
        available_codecs = []
        
        for codec in codecs:
            try:
                fourcc = cv2.VideoWriter_fourcc(*codec)
                test_writer = cv2.VideoWriter('test.avi', fourcc, 25, (100, 100))
                if test_writer.isOpened():
                    available_codecs.append(codec)
                    print(f"     âœ“ {codec}")
                else:
                    print(f"     âœ— {codec}")
                test_writer.release()
                try:
                    os.remove('test.avi')
                except:
                    pass
            except Exception as e:
                print(f"     âœ— {codec} - bÅ‚Ä…d: {e}")
        
        return available_codecs
    
    def check_ffmpeg(self):
        """SprawdÅº dostÄ™pnoÅ›Ä‡ FFmpeg"""
        try:
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                version_line = result.stdout.split('\n')[0]
                print(f"âœ“ FFmpeg dostÄ™pny: {version_line}")
                return True
        except:
            pass
        
        print("âœ— FFmpeg niedostÄ™pny")
        return False
    
    def process_video_smooth(self, input_path, output_path):
        """Przetwarzanie z niezawodnÄ… metodÄ… alternative"""
        print(f"ğŸ¬ Rozpoczynam Å‚agodne przetwarzanie: {input_path}")
        
        # Diagnostyka
        available_codecs = self.diagnose_opencv()
        has_ffmpeg = self.check_ffmpeg()
        
        if not available_codecs and not has_ffmpeg:
            print("âœ— Brak dostÄ™pnych metod zapisu wideo!")
            return False
        
        # Informacje o wideo
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            print("âœ— Nie moÅ¼na otworzyÄ‡ pliku wejÅ›ciowego")
            return False
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"ğŸ“¹ Wideo: {width}x{height} @ {fps:.2f} FPS, {frame_count} klatek")
        print(f"ğŸ¨ Metoda wzmocnienia: alternative (histogram stretching)")
        cap.release()
        
        # UÅ¼ywamy tylko niezawodnej metody alternative
        enhance_func = self.enhance_frame_alternative
        
        # Strategia zapisu - najpierw klatki, potem FFmpeg
        if has_ffmpeg:
            return self.process_via_frames_ffmpeg(input_path, output_path, enhance_func)
        
        return False
    
    def process_via_frames_ffmpeg(self, input_path, output_path, enhance_func):
        """Przetwarzanie przez klatki i FFmpeg"""
        print("ğŸ¯ Strategia: Klatki -> FFmpeg")
        
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        frames_dir = os.path.join(self.temp_dir, 'frames')
        os.makedirs(frames_dir, exist_ok=True)
        
        frame_count = 0
        success_count = 0
        
        print("ğŸ“¸ Przetwarzanie klatek...")
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            try:
                # Wzmocnienie wybranÄ… metodÄ…
                enhanced = enhance_func(frame)
                
                if enhanced is not None:
                    # Zapis jako PNG dla lepszej jakoÅ›ci
                    frame_path = os.path.join(frames_dir, f'frame_{frame_count:06d}.png')
                    success = cv2.imwrite(frame_path, enhanced, 
                                        [cv2.IMWRITE_PNG_COMPRESSION, 1])  # Minimalna kompresja
                    
                    if success:
                        success_count += 1
                
                frame_count += 1
                
                if frame_count % 30 == 0:
                    print(f"   ğŸ“Š PostÄ™p: {success_count}/{frame_count} klatek")
                    
            except Exception as e:
                print(f"âš ï¸ BÅ‚Ä…d przetwarzania klatki {frame_count}: {e}")
        
        cap.release()
        print(f"âœ… Przetworzono {success_count}/{frame_count} klatek")
        
        # Konwersja do wideo przez FFmpeg
        if success_count > 0:
            return self.frames_to_video_ffmpeg(frames_dir, output_path, fps, 'png')
        
        return False
    
    def frames_to_video_ffmpeg(self, frames_dir, output_path, fps, ext='png'):
        """Konwersja klatek do wideo przez FFmpeg z wysokÄ… jakoÅ›ciÄ…"""
        print("ğŸ¬ Tworzenie wideo z klatek przez FFmpeg...")
        
        input_pattern = os.path.join(frames_dir, f'frame_%06d.{ext}')
        cmd = [
            'ffmpeg', '-y',
            '-framerate', str(fps),
            '-i', input_pattern,
            '-c:v', 'libx264',
            '-preset', 'slow',      # Lepsza kompresja
            '-crf', '15',           # Bardzo wysoka jakoÅ›Ä‡ (0-51, niÅ¼sza = lepsza)
            '-pix_fmt', 'yuv420p',
            '-movflags', '+faststart',  # Szybsze Å‚adowanie
            output_path
        ]
        
        try:
            print(f"   ğŸ“ Komenda: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                print(f"âœ… FFmpeg sukces: {output_path}")
                return True
            else:
                print(f"âœ— FFmpeg bÅ‚Ä…d: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print("âœ— FFmpeg timeout")
            return False
        except Exception as e:
            print(f"âœ— FFmpeg exception: {e}")
            return False
    
    def cleanup(self):
        """WyczyÅ›Ä‡ pliki tymczasowe"""
        try:
            import shutil
            shutil.rmtree(self.temp_dir)
            print(f"ğŸ§¹ Wyczyszczono: {self.temp_dir}")
        except Exception as e:
            print(f"âš ï¸ BÅ‚Ä…d czyszczenia: {e}")

def main():
    if len(sys.argv) < 2:
        print("ğŸ¬ Åagodny Wzmacniacz Wideo")
        print("UÅ¼ycie: python3 smooth_video_enhancer.py <input.mp4> [output.mp4] [metoda]")
        print("")
        print("Metody wzmocnienia:")
        print("  smooth      - Å‚agodne wzmocnienie (domyÅ›lne)")
        print("  alternative - histogram stretching")
        print("  compare     - automatyczny wybÃ³r najlepszej")
        print("")
        print("Funkcje:")
        print("- Eliminuje ostre strefy i artefakty")
        print("- Zachowuje naturalne przejÅ›cia")
        print("- Adaptacyjne wzmocnienie bazowane na zawartoÅ›ci")
        print("- Selektywne wyostrzanie tylko na krawÄ™dziach")
        return
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "smooth_" + os.path.basename(input_file)
    method = sys.argv[3] if len(sys.argv) > 3 else 'smooth'
    
    if not os.path.exists(input_file):
        print(f"âœ— Plik {input_file} nie istnieje")
        return
    
    enhancer = SmoothVideoEnhancer()
    
    try:
        success = enhancer.process_video_smooth(input_file, output_file)
        if success:
            print(f"\nğŸ‰ Sukces! SprawdÅº wyniki: {output_file}")
            print("ğŸ“Š Wideo zostaÅ‚o przetworzone z zachowaniem naturalnych przejÅ›Ä‡")
        else:
            print(f"\nğŸ’¥ Przetwarzanie nie powiodÅ‚o siÄ™")
    finally:
        enhancer.cleanup()

if __name__ == "__main__":
    main()